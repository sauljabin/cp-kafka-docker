<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Kafka Sandbox</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Setup</li><li class="chapter-item expanded "><a href="dependencies.html"><strong aria-hidden="true">1.</strong> Intall Dependencies</a></li><li class="chapter-item expanded "><a href="quick-start.html"><strong aria-hidden="true">2.</strong> Quick Start</a></li><li class="chapter-item expanded affix "><li class="part-title">Setting Up Some Tools</li><li class="chapter-item expanded "><a href="tools/kafka-cli-tools.html"><strong aria-hidden="true">3.</strong> Kafka CLI Tools</a></li><li class="chapter-item expanded "><a href="tools/sql-database.html"><strong aria-hidden="true">4.</strong> SQL Database</a></li><li class="chapter-item expanded "><a href="tools/sql-populate-database.html"><strong aria-hidden="true">5.</strong> SQL Populate Database</a></li><li class="chapter-item expanded "><a href="tools/nosql-database.html"><strong aria-hidden="true">6.</strong> NoSQL Database</a></li><li class="chapter-item expanded "><a href="tools/nosql-populate-database.html"><strong aria-hidden="true">7.</strong> NoSQL Populate Database</a></li><li class="chapter-item expanded "><a href="tools/mqtt-cli-tools.html"><strong aria-hidden="true">8.</strong> MQTT CLI Tools</a></li><li class="chapter-item expanded "><a href="tools/mqtt-broker.html"><strong aria-hidden="true">9.</strong> MQTT Broker</a></li><li class="chapter-item expanded "><a href="tools/portainer.html"><strong aria-hidden="true">10.</strong> Portainer</a></li><li class="chapter-item expanded affix "><li class="part-title">Using Kafka</li><li class="chapter-item expanded "><a href="using-kafka/kafka-cluster.html"><strong aria-hidden="true">11.</strong> Kafka Cluster</a></li><li class="chapter-item expanded "><a href="using-kafka/kafka-akhq.html"><strong aria-hidden="true">12.</strong> Kafka AKHQ</a></li><li class="chapter-item expanded "><a href="using-kafka/kafka-schema-registry.html"><strong aria-hidden="true">13.</strong> Kafka Schema Registry</a></li><li class="chapter-item expanded "><a href="using-kafka/kafka-connect/kafka-connect.html"><strong aria-hidden="true">14.</strong> Kafka Connect</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="using-kafka/kafka-connect/database-example.html"><strong aria-hidden="true">14.1.</strong> Database Example</a></li><li class="chapter-item expanded "><a href="using-kafka/kafka-connect/mqtt-example.html"><strong aria-hidden="true">14.2.</strong> MQTT Example</a></li></ol></li><li class="chapter-item expanded "><a href="using-kafka/kafka-ksqldb/kafka-ksqldb.html"><strong aria-hidden="true">15.</strong> Kafka ksqlDB</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="using-kafka/kafka-ksqldb/extensions.html"><strong aria-hidden="true">15.1.</strong> Extensions</a></li></ol></li><li class="chapter-item expanded "><a href="using-kafka/kafka-clients/kafka-clients.html"><strong aria-hidden="true">16.</strong> Kafka Clients</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="using-kafka/kafka-clients/avro-producer-and-consumer.html"><strong aria-hidden="true">16.1.</strong> Avro Producer and Consumer</a></li><li class="chapter-item expanded "><a href="using-kafka/kafka-clients/streams.html"><strong aria-hidden="true">16.2.</strong> Streams</a></li><li class="chapter-item expanded "><a href="using-kafka/kafka-clients/spring-boot.html"><strong aria-hidden="true">16.3.</strong> Spring Boot</a></li></ol></li><li class="chapter-item expanded "><a href="using-kafka/kafka-performance-tools.html"><strong aria-hidden="true">17.</strong> Kafka Performance Tools</a></li><li class="chapter-item expanded affix "><li class="part-title">Proxies</li><li class="chapter-item expanded "><a href="proxies/kafka-rest-proxy.html"><strong aria-hidden="true">18.</strong> Kafka REST Proxy</a></li><li class="chapter-item expanded "><a href="proxies/kafka-mqtt-proxy.html"><strong aria-hidden="true">19.</strong> Kafka MQTT Proxy</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><a href="using-kafka/ports-table.html">Ports Table</a></li><li class="chapter-item expanded affix "><a href="book.html">About this book</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Kafka Sandbox</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/sauljabin/kafka-sandbox" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p><strong>Kafka Sandbox</strong> helps you to deploy a kafka sandbox locally. It intends to be a simple way to get started with kafka and
help you on your learning path. It provides you with a wide variety of tools from the kafka ecosystem and a simple way
to run them all. It also includes a set of tools and tips to make it easier for you to use kafka. It does not include
security since it is not a production system.</p>
<h2 id="interesting-links"><a class="header" href="#interesting-links">Interesting Links</a></h2>
<ul>
<li><a href="https://developer.confluent.io/learn-kafka/">Confluent free courses</a></li>
<li><a href="https://docs.confluent.io/platform/current/installation/docker/image-reference.html">Confluent docker images references</a></li>
<li><a href="https://docs.confluent.io/platform/current/installation/versions-interoperability.html">Confluent versions interoperability</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="intall-dependencies"><a class="header" href="#intall-dependencies">Intall Dependencies</a></h1>
<ul>
<li><a href="https://www.docker.com/">docker</a> - version 20 or higher</li>
<li><a href="https://docs.docker.com/compose/cli-command/">docker compose</a> - version 2 or higher</li>
<li><a href="https://www.java.com/en/download/">java</a> - version 11 or higher</li>
<li><a href="https://httpie.io/">httpie</a> - rest client</li>
<li><a href="https://stedolan.github.io/jq/">jq</a> - json parser</li>
</ul>
<h2 id="other-useful-utilities"><a class="header" href="#other-useful-utilities">Other Useful Utilities</a></h2>
<ul>
<li><a href="https://curl.se/">curl</a> - command line http client</li>
<li><a href="https://github.com/jesseduffield/lazydocker#installation">lazydocker</a> - docker text user interface</li>
<li><a href="https://github.com/sauljabin/kaskade#installation-and-usage">kaskade</a> - kafka text user interface</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<p>Clone the repo:</p>
<pre><code class="language-bash">git clone https://github.com/sauljabin/kafka-sandbox.git
cd kafka-sandbox
</code></pre>
<p>Create a docker network:</p>
<pre><code class="language-bash">docker network create kafka-sandbox_network
</code></pre>
<p>Run the kafka cluster:</p>
<pre><code class="language-bash">cd kafka-cluster
docker compose up -d
</code></pre>
<p>Run AKHQ:</p>
<pre><code class="language-bash">cd kafka-akhq
docker compose up -d
</code></pre>
<p>Open AKHQ at <a href="http://localhost:8080/">http://localhost:8080/</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-cli-tools"><a class="header" href="#kafka-cli-tools">Kafka CLI Tools</a></h1>
<p>It is a collection of tools to interact with kafka cluster through the terminal.</p>
<ul>
<li><a href="https://github.com/edenhill/kafkacat">kafkacat</a></li>
<li><a href="https://adevinta.github.io/zoe/">zoe</a></li>
<li><a href="https://docs.confluent.io/platform/current/installation/installing_cp/zip-tar.html">confluent community tools</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-cli">kafka-cli</a></li>
</ul>
<blockquote>
<p>⚠ Run these commands inside the root folder.</p>
</blockquote>
<p>Create an alias for <code>kafka-cli</code>:</p>
<pre><code class="language-bash">alias kafka-cli='docker run --rm -it --network kafka-sandbox_network kafka-cli:latest '
</code></pre>
<p>To permanently add the alias to your shell (<code>~/.bashrc</code> or <code>~/.zshrc</code> file):</p>
<pre><code class="language-bash">echo &quot;alias kafka-cli='docker run --rm -it --network kafka-sandbox_network kafka-cli:latest '&quot; &gt;&gt; ~/.zshrc
</code></pre>
<p>Create the docker image:</p>
<pre><code class="language-bash">cd kafka-cli
docker build -t kafka-cli:latest .
kafka-cli
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sql-database"><a class="header" href="#sql-database">SQL Database</a></h1>
<p>Create a MySQL and PostgresSQL instance and a database.</p>
<ul>
<li><a href="https://hub.docker.com/_/mysql">mysql</a></li>
<li><a href="https://hub.docker.com/_/postgres">postgres</a></li>
<li><a href="https://hub.docker.com/_/adminer">adminer</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/sql-database">sql-database</a></li>
<li>postgres port: <code>5432</code></li>
<li>mysql port: <code>3306</code></li>
<li>adminer port: <code>9090</code> (<a href="http://localhost:9090/">open it in the web browser</a>)</li>
</ul>
<p>Run MySQL, PostgresSQL and Adminer:</p>
<pre><code class="language-bash">cd sql-database
docker compose up -d
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sql-populate-database"><a class="header" href="#sql-populate-database">SQL Populate Database</a></h1>
<p>This tool helps to populate either a MySQL or PostgresSQL database with random customers. This is an ancillary project
that can help us to set different scenarios.</p>
<ul>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/sql-populate">sql-populate</a></li>
</ul>
<blockquote>
<p>⚠ Run these commands inside the root folder.</p>
</blockquote>
<p>Create an alias for <code>sql-populate</code>:</p>
<pre><code class="language-bash">alias sql-populate=&quot;$PWD/sql-populate/build/install/sql-populate/bin/sql-populate &quot;
</code></pre>
<p>To permanently add the alias to your shell (<code>~/.bashrc</code> or <code>~/.zshrc</code> file):</p>
<pre><code class="language-bash">echo &quot;alias sql-populate='$PWD/sql-populate/build/install/sql-populate/bin/sql-populate '&quot; &gt;&gt; ~/.zshrc
</code></pre>
<p>Install the app:</p>
<pre><code class="language-bash">./gradlew sql-populate:install
sql-populate
</code></pre>
<p>Examples:</p>
<pre><code class="language-bash">sql-populate --url &quot;jdbc:mysql://localhost:3306/sandbox&quot; --user &quot;root&quot; --password &quot;notasecret&quot; 100
sql-populate --url &quot;jdbc:postgresql://localhost:5432/sandbox&quot; --user &quot;postgres&quot; --password &quot;notasecret&quot; 100
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nosql-database"><a class="header" href="#nosql-database">NoSQL Database</a></h1>
<p>Create a MongoDB instance and a database.</p>
<ul>
<li><a href="https://hub.docker.com/_/mongo">mongo</a></li>
<li><a href="https://hub.docker.com/_/mongo-express">mongo express</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/nosql-database">nosql-database</a></li>
<li>mongo port: <code>27017</code></li>
<li>mongo express port: <code>7070</code> (<a href="http://localhost:7070/">open it in the web browser</a>)</li>
</ul>
<p>Run MongoDB and Mongo Express:</p>
<pre><code class="language-bash">cd nosql-database
docker compose up -d
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nosql-populate-database"><a class="header" href="#nosql-populate-database">NoSQL Populate Database</a></h1>
<p>This tool helps to populate MongoDB with random customers. This is an ancillary project that can help us to set
different scenarios.</p>
<ul>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/nosql-populate">nosql-populate</a></li>
</ul>
<blockquote>
<p>⚠ Run these commands inside the root folder.</p>
</blockquote>
<p>Create an alias for <code>nosql-populate</code>:</p>
<pre><code class="language-bash">alias nosql-populate=&quot;$PWD/nosql-populate/build/install/nosql-populate/bin/nosql-populate &quot;
</code></pre>
<p>To permanently add the alias to your shell (<code>~/.bashrc</code> or <code>~/.zshrc</code> file):</p>
<pre><code class="language-bash">echo &quot;alias nosql-populate='$PWD/nosql-populate/build/install/nosql-populate/bin/nosql-populate '&quot; &gt;&gt; ~/.zshrc
</code></pre>
<p>Install the app:</p>
<pre><code class="language-bash">./gradlew nosql-populate:install
nosql-populate
</code></pre>
<p>Example:</p>
<pre><code class="language-bash">nosql-populate --url &quot;mongodb://root:notasecret@localhost:27017&quot; -d &quot;sandbox&quot; 100
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mqtt-cli-tools"><a class="header" href="#mqtt-cli-tools">MQTT CLI Tools</a></h1>
<p>MQTT collection of tools to interact with a MQTT broker.</p>
<ul>
<li><a href="https://hivemq.github.io/mqtt-cli/">mqtt-cli</a></li>
</ul>
<blockquote>
<p>⚠ Run these commands inside the root folder.</p>
</blockquote>
<p>Create an alias for <code>mqtt-cli</code>:</p>
<pre><code class="language-bash">alias mqtt-cli='docker run --rm -it --network kafka-sandbox_network hivemq/mqtt-cli:latest '
</code></pre>
<p>To permanently add the alias to your shell (<code>~/.bashrc</code> or <code>~/.zshrc</code> file):</p>
<pre><code class="language-bash">echo &quot;alias mqtt-cli='docker run --rm -it --network kafka-sandbox_network hivemq/mqtt-cli:latest '&quot; &gt;&gt; ~/.zshrc
</code></pre>
<p>Test the cli:</p>
<pre><code class="language-bash">mqtt-cli
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mqtt-broker"><a class="header" href="#mqtt-broker">MQTT Broker</a></h1>
<p>Eclipse Mosquitto is an open source (EPL/EDL licensed) message broker that implements the MQTT protocol versions 5.0,
3.1.1 and 3.1. Mosquitto is lightweight and is suitable for use on all devices from low power single board computers to
full servers.</p>
<ul>
<li><a href="https://mosquitto.org/">mosquitto</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/mqtt-broker">mqtt-broker</a></li>
<li>mosquitto port: <code>1883</code></li>
</ul>
<p>Run Mosquitto:</p>
<pre><code class="language-bash">cd mqtt-broker
docker compose up -d
mqtt-cli test -h mosquitto
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="portainer"><a class="header" href="#portainer">Portainer</a></h1>
<p>It's a docker web UI that allows you to manage your docker containers.</p>
<ul>
<li><a href="https://documentation.portainer.io/v2.0/deploy/ceinstalldocker/">portainer</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/docker-portainer">docker-portainer</a></li>
<li>portainer port: <code>9000</code> (<a href="http://localhost:9000/">open it in the web browser</a>)</li>
</ul>
<p>Run Portainer:</p>
<pre><code class="language-bash">cd docker-portainer
docker compose up -d
</code></pre>
<p>Open Portainer at <a href="http://localhost:9000/">http://localhost:9000/</a></p>
<blockquote>
<p>⚠ User: <code>admin</code> and password: <code>notasecret</code>.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-cluster"><a class="header" href="#kafka-cluster">Kafka Cluster</a></h1>
<p>A three node kafka cluster.</p>
<ul>
<li><a href="https://kafka.apache.org/">kafka</a></li>
<li><a href="https://docs.confluent.io/platform/current/installation/configuration/broker-configs.html">kafka settings</a></li>
<li><a href="https://zookeeper.apache.org/">zookeeper</a></li>
<li><a href="https://docs.confluent.io/platform/current/zookeeper/deployment.html">zookeeper settings</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-cluster">kafka-cluster</a></li>
<li>kafka version: <a href="https://docs.confluent.io/platform/current/installation/versions-interoperability.html">cp 7.1.1</a></li>
<li>kafka ports: <code>19093</code>, <code>29093</code>, <code>39093</code></li>
<li>zookeeper ports: <code>12181</code>, <code>22181</code>, <code>32181</code></li>
</ul>
<p>Run Kafka and Zookeeper:</p>
<pre><code class="language-bash">cd kafka-cluster
docker compose up -d
kafka-cli kafka-topics --bootstrap-server kafka1:9092 --list
</code></pre>
<p>Create a topic:</p>
<pre><code class="language-bash">kafka-cli kafka-topics --create --bootstrap-server kafka1:9092 \
                       --replication-factor 3 \
                       --partitions 3 \
                       --topic kafka-cluster.test
</code></pre>
<p>Produce a message:</p>
<pre><code class="language-bash">kafka-cli kafka-console-producer --broker-list kafka1:9092 --topic kafka-cluster.test
</code></pre>
<p>Consume messages:</p>
<pre><code class="language-bash">kafka-cli kafka-console-consumer --from-beginning --group kafka-cluster.test \
                                 --topic kafka-cluster.test  \
                                 --bootstrap-server kafka1:9092
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-akhq"><a class="header" href="#kafka-akhq">Kafka AKHQ</a></h1>
<p>UI for managing kafka cluster.</p>
<ul>
<li><a href="https://akhq.io/">akhq</a></li>
<li><a href="https://github.com/tchiotludo/akhq#kafka-cluster-configuration">akhq settings</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-akhq">kafka-akhq</a></li>
<li>akhq port: <code>8080</code> (<a href="http://localhost:8080/">open it in the web browser</a>)</li>
</ul>
<p>Run AKHQ:</p>
<pre><code class="language-bash">cd kafka-akhq
docker compose up -d
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-schema-registry"><a class="header" href="#kafka-schema-registry">Kafka Schema Registry</a></h1>
<p>It provides a RESTful interface for storing and retrieving your Avro, JSON Schema, and Protobuf schemas.</p>
<ul>
<li><a href="https://docs.confluent.io/platform/current/schema-registry/index.html">schema registry</a></li>
<li><a href="https://docs.confluent.io/platform/current/schema-registry/installation/config.html">schema registry settings</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-schema-registry">kafka-schema-registry</a></li>
<li>schema registry port: <code>8081</code></li>
</ul>
<p>Run Schema Registry:</p>
<pre><code class="language-bash">cd kafka-schema-registry
docker compose up -d
http :8081/config
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-connect"><a class="header" href="#kafka-connect">Kafka Connect</a></h1>
<p>It makes it simple to quickly define connectors that move large data sets into and out of Kafka.</p>
<ul>
<li><a href="https://docs.confluent.io/current/connect/index.html">connect</a></li>
<li><a href="https://docs.confluent.io/platform/current/installation/configuration/connect/index.html">connect settings</a></li>
<li><a href="https://docs.confluent.io/platform/current/connect/references/restapi.html">connect api reference</a></li>
<li><a href="https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc">jdbc connector plugin</a></li>
<li><a href="https://www.confluent.io/hub/mongodb/kafka-connect-mongodb">mongo connector plugin</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-connect">kafka-connect</a></li>
<li>plugins location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-connect/plugins">kafka-connect/plugins</a></li>
<li>requests location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-connect/requests">kafka-connect/requests</a></li>
<li>connect port: <code>8083</code></li>
</ul>
<p>Run Kafka Connect:</p>
<pre><code class="language-bash">cd kafka-connect
docker compose up -d
http :8083/connector-plugins
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-connect-database-example"><a class="header" href="#kafka-connect-database-example">Kafka Connect Database Example</a></h1>
<blockquote>
<p>⚠ This example does not support deletion, for that you have to implement tombstone events at the <a href="https://debezium.io/documentation/reference/connectors/postgresql.html#postgresql-tombstone-events">source</a> and <a href="https://docs.confluent.io/kafka-connect-jdbc/current/sink-connector/index.html#jdbc-sink-delete-mode">sink</a>.</p>
</blockquote>
<p>Populate the databases:</p>
<pre><code class="language-bash">sql-populate --url &quot;jdbc:mysql://localhost:3306/sandbox&quot; --user &quot;root&quot; --password &quot;notasecret&quot; 100
</code></pre>
<p>Create the connectors using the API:</p>
<pre><code class="language-bash">cd kafka-connect
http :8083/connectors &lt; requests/create-connector-mysql-source.json
http :8083/connectors &lt; requests/create-connector-mongo-sink.json
http :8083/connectors &lt; requests/create-connector-postgres-sink.json
</code></pre>
<p>For deleting the connectors:</p>
<pre><code class="language-bash">http DELETE :8083/connectors/postgres-sink
http DELETE :8083/connectors/mongo-sink
http DELETE :8083/connectors/mysql-source
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-connect-mqtt-example"><a class="header" href="#kafka-connect-mqtt-example">Kafka Connect MQTT Example</a></h1>
<p>Subscribe to topics (for debugging purposes):</p>
<pre><code class="language-bash">mqtt-cli sub -h mosquitto -t 'house/+/brightness'
</code></pre>
<p>Create a connector using the API:</p>
<pre><code class="language-bash">cd kafka-connect
http :8083/connectors &lt; requests/create-connector-mqtt-source.json
</code></pre>
<p>Publish messages:</p>
<pre><code class="language-bash">mqtt-cli pub -h mosquitto -t 'house/room/brightness' -m '800LM'
mqtt-cli pub -h mosquitto -t 'house/kitchen/brightness' -m '1000LM'
</code></pre>
<p>Consuming the data:</p>
<pre><code class="language-bash">kafka-cli kafka-console-consumer --from-beginning --group kafka-connect.brightness_consumer \
                                 --topic kafka-connect.brightness  \
                                 --bootstrap-server kafka1:9092 \
                                 --property print.key=true
</code></pre>
<p>For deleting the connector:</p>
<pre><code class="language-bash">http DELETE :8083/connectors/mqtt-source
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-ksqldb"><a class="header" href="#kafka-ksqldb">Kafka ksqlDB</a></h1>
<p>ksqlDB is a database that's purpose-built for stream processing applications.</p>
<blockquote>
<p>⚠ ksqlDB it is not a SQL database, it provides an extra layer for implementing kstream, ktable and connectors through a language (ksql) based on sql.</p>
</blockquote>
<ul>
<li><a href="https://ksqldb.io/">ksqldb</a></li>
<li><a href="https://docs.ksqldb.io/en/latest/reference/server-configuration/">ksqldb settings</a></li>
<li><a href="https://docs.ksqldb.io/en/latest/how-to-guides/test-an-app/">ksqldb test runner</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-ksqldb">kafka-ksqldb</a></li>
<li>statements location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-ksqldb/statements">kafka-ksqldb/statements</a></li>
<li>test location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-ksqldb/tests">kafka-ksqldb/tests</a></li>
<li>extensions location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-ksqldb-extensions/extensions">kafka-ksqldb-extensions/extensions</a></li>
<li>ksqldb port: <code>8088</code></li>
</ul>
<p>Create an alias for <code>ksqldb-cli</code>:</p>
<blockquote>
<p>⚠ Run alias commands inside the root folder.</p>
</blockquote>
<pre><code class="language-bash">alias ksqldb-cli=&quot;docker run --rm -it --network kafka-sandbox_network --workdir /ksqldb -v $PWD/kafka-ksqldb/tests:/ksqldb/tests -v $PWD/kafka-ksqldb/statements:/ksqldb/statements -v $PWD/kafka-ksqldb-extensions/extensions:/ksqldb/extensions kafka-cli:latest &quot;
</code></pre>
<p>To permanently add the alias to your shell (<code>~/.bashrc</code> or <code>~/.zshrc</code> file):</p>
<pre><code class="language-bash">echo &quot;alias ksqldb-cli='docker run --rm -it --network kafka-sandbox_network --workdir /ksqldb -v $PWD/kafka-ksqldb/tests:/ksqldb/tests -v $PWD/kafka-ksqldb/statements:/ksqldb/statements -v $PWD/kafka-ksqldb-extensions/extensions:/ksqldb/extensions kafka-cli:latest '&quot; &gt;&gt; ~/.zshrc
</code></pre>
<p>Run ksqlDB:</p>
<pre><code class="language-bash">cd kafka-ksqldb
docker compose up -d
http :8088/info
ksqldb-cli ksql -e &quot;SHOW STREAMS;&quot; http://ksqldb:8088
</code></pre>
<p>Test runner:</p>
<pre><code class="language-bash">ksqldb-cli ksql-test-runner -e extensions/ \
                            -s statements/create-orders.ksql \
                            -i tests/orders-input.json \
                            -o tests/orders-output.json | grep '&gt;&gt;&gt;'
</code></pre>
<p>Execute statement files:</p>
<pre><code class="language-bash">ksqldb-cli ksql -f statements/create-orders.ksql http://ksqldb:8088
ksqldb-cli ksql -f statements/insert-orders.ksql http://ksqldb:8088
</code></pre>
<p>Deleting all orders:</p>
<pre><code class="language-bash">ksqldb-cli ksql -e &quot;DROP STREAM ORDERSIZES DELETE TOPIC; DROP STREAM ORDERS DELETE TOPIC;&quot; http://ksqldb:8088
</code></pre>
<p>Interactive ksqlDB shell:</p>
<pre><code class="language-bash">ksqldb-cli ksql http://ksqldb:8088
SHOW STREAMS;
</code></pre>
<p>Using the ksqlDB API, list of streams:</p>
<pre><code class="language-bash">http :8088/ksql ksql=&quot;list streams;&quot; | jq '.[].streams[] | [{name: .name, topic: .topic}]'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ksqldb-extensions"><a class="header" href="#ksqldb-extensions">ksqlDB Extensions</a></h1>
<p>ksqlDB extensions are pieces of logic for transforming or aggregating events that ksqlDB can't currently express.</p>
<ul>
<li><a href="https://docs.ksqldb.io/en/latest/how-to-guides/create-a-user-defined-function">ksqldb extensions (udf, udtf, udaf)</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-ksqldb-extensions">kafka-ksqldb-extensions</a></li>
</ul>
<p>Check the <a href="using-kafka/kafka-ksqldb/extensions.html#kafka-ksqldb">Kafka ksqlDB</a> section.</p>
<p>For creating the <code>jar</code> extension, you can use the following command (development purposes):</p>
<pre><code class="language-bash">./gradlew kafka-ksqldb-extensions:shadowJar
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-clients"><a class="header" href="#kafka-clients">Kafka Clients</a></h1>
<p>Java examples for producing and consuming messages from Kafka using the
<a href="https://docs.confluent.io/clients-kafka-java/current/overview.html">java kafka client</a> lib.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="avro-producer-and-consumer"><a class="header" href="#avro-producer-and-consumer">Avro Producer and Consumer</a></h1>
<p>These examples produce and consume messages from the <code>supplier</code> topic. The producer example produces random suppliers.</p>
<ul>
<li><a href="https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-avro.html">kafka producer and consumer example</a></li>
<li><a href="https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html">kafka consumer settings</a></li>
<li><a href="https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html">kafka producer settings</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-clients">kafka-clients</a></li>
</ul>
<blockquote>
<p>⚠ Run these commands inside the root folder.</p>
</blockquote>
<p>Create an alias for <code>kafka-clients</code>:</p>
<pre><code class="language-bash">alias kafka-clients=&quot;$PWD/kafka-clients/build/install/kafka-clients/bin/kafka-clients &quot;
</code></pre>
<p>To permanently add the alias to your shell (<code>~/.bashrc</code> or <code>~/.zshrc</code> file):</p>
<pre><code class="language-bash">echo &quot;alias kafka-clients='$PWD/kafka-clients/build/install/kafka-clients/bin/kafka-clients '&quot; &gt;&gt; ~/.zshrc
</code></pre>
<p>Create a topic:</p>
<pre><code class="language-bash">kafka-cli kafka-topics --create --bootstrap-server kafka1:9092 \
                       --replication-factor 3 \
                       --partitions 3 \
                       --topic kafka-clients.suppliers
</code></pre>
<p>Install the app:</p>
<pre><code class="language-bash">./gradlew kafka-clients:install
kafka-clients
</code></pre>
<p>Run clients:</p>
<pre><code class="language-bash">kafka-clients producer 100
kafka-clients consumer
</code></pre>
<p>For creating a AVRO schema, you can use the following command (development purposes):</p>
<pre><code class="language-bash">./gradlew kafka-clients:generateAvro
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="streams"><a class="header" href="#streams">Streams</a></h1>
<p>Kafka Streams is a client library providing organizations with a particularly efficient framework for processing
streaming data. It offers a streamlined method for creating applications and microservices that must process data in
real-time to be effective.</p>
<p>Check the <a href="using-kafka/kafka-clients/streams.html#kafka-clients---avro-producer-and-consumer">Kafka Clients - Avro Producer and Consumer</a> section.</p>
<ul>
<li><a href="https://kafka.apache.org/documentation/streams/">kafka streams</a></li>
<li><a href="https://github.com/confluentinc/kafka-streams-examples">kafka streams examples</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-clients">kafka-clients</a></li>
</ul>
<p>Run streams:</p>
<pre><code class="language-bash">kafka-clients streams
</code></pre>
<p>Print results:</p>
<pre><code class="language-bash">kafka-cli kafka-console-consumer --from-beginning --group kafka-streams.consumer \
                                 --topic kafka-streams.supplier_counts_by_country  \
                                 --bootstrap-server kafka1:9092 \
                                 --property print.key=true \
                                 --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="spring-boot"><a class="header" href="#spring-boot">Spring Boot</a></h1>
<p>Spring Boot + Spring Kafka producer and consumer examples.</p>
<ul>
<li><a href="https://www.confluent.io/blog/apache-kafka-spring-boot-application/">confluent spring kafka examples</a></li>
<li><a href="https://docs.spring.io/spring-kafka/reference/html/">spring kafka settings</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-spring-boot">kafka-spring-boot</a></li>
<li>spring port: <code>8585</code></li>
</ul>
<blockquote>
<p>⚠ Run these commands inside the root folder.</p>
</blockquote>
<p>Run spring boot:</p>
<pre><code class="language-bash">./gradlew kafka-spring-boot:bootRun
</code></pre>
<p>In another terminal:</p>
<pre><code class="language-bash">http :8585/actuator/health
http :8585/produce messages==10
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-performance-tools"><a class="header" href="#kafka-performance-tools">Kafka Performance Tools</a></h1>
<p>Performance tuning involves two important metrics:</p>
<ul>
<li>Latency measures how long it takes to process one event.</li>
<li>Throughput measures how many events arrive within a specific amount of time.</li>
</ul>
<p>Run help:</p>
<pre><code class="language-bash">kafka-cli kafka-producer-perf-test --help
kafka-cli kafka-consumer-perf-test --help
</code></pre>
<p>Create a topic:</p>
<pre><code class="language-bash">kafka-cli kafka-topics --create --bootstrap-server kafka1:9092 \
                       --replication-factor 3 \
                       --partitions 3 \
                       --topic kafka-cluster.performance-test
</code></pre>
<h2 id="performance-tests"><a class="header" href="#performance-tests">Performance Tests</a></h2>
<p>Test producer:</p>
<pre><code class="language-bash">kafka-cli kafka-producer-perf-test --topic kafka-cluster.performance-test \
                                   --throughput -1 \
                                   --num-records 3000000 \
                                   --record-size 1024 \
                                   --producer-props acks=all bootstrap.servers=kafka1:9092,kafka2:9092,kafka3:9092
</code></pre>
<ul>
<li>Throughput in MB/sec.</li>
<li>Latency in miliseconds.</li>
</ul>
<p>Test consumer:</p>
<pre><code class="language-bash">kafka-cli kafka-consumer-perf-test --topic kafka-cluster.performance-test \
                                   --broker-list kafka1:9092,kafka2:9092,kafka3:9092 \
                                   --messages 3000000
</code></pre>
<ul>
<li><code>start.time, end.time</code>: shows test start and end time.</li>
<li><code>data.consumed.in.MB</code>: shows the size of all messages consumed.</li>
<li><code>MB.sec</code>: shows how much data transferred in megabytes per second (Throughput on size).</li>
<li><code>data.consumed.in.nMsg</code>: shows the count of the total messages consumed during this test.</li>
<li><code>nMsg.sec</code>: shows how many messages were consumed in a second (Throughput on the count of messages).</li>
</ul>
<p>Test end to end latency:</p>
<pre><code class="language-bash">kafka-cli kafka-run-class kafka.tools.EndToEndLatency kafka1:9092,kafka2:9092,kafka3:9092 kafka-cluster.performance-test 10000 1 1024
</code></pre>
<ul>
<li>This class records the average end to end latency for a single message to travel through Kafka.</li>
<li>Latency in miliseconds.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-rest-proxy"><a class="header" href="#kafka-rest-proxy">Kafka REST Proxy</a></h1>
<p>The Kafka REST Proxy provides a RESTful interface to a Kafka cluster.</p>
<blockquote>
<p>⚠ Use this when you really need a rest interface since it is usually more complex than using conventional kafka clients.</p>
</blockquote>
<ul>
<li><a href="https://docs.confluent.io/platform/current/kafka-rest/index.html">kafka rest</a></li>
<li><a href="https://docs.confluent.io/platform/current/kafka-rest/production-deployment/rest-proxy/config.html">kafka rest settings</a></li>
<li><a href="https://docs.confluent.io/platform/current/kafka-rest/api.html">kafka rest api reference</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-rest">kafka-rest</a></li>
<li>requests location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-rest/requests">kafka-rest/requests</a></li>
<li>kafka rest port: <code>8082</code></li>
</ul>
<p>Run Kafka REST Proxy:</p>
<pre><code class="language-bash">cd kafka-rest
docker compose up -d
http :8082/brokers
</code></pre>
<p>Create topics:</p>
<pre><code class="language-bash">cd kafka-rest
http :8082/topics/kafka-rest.test Content-Type:application/vnd.kafka.json.v2+json records:='[{ &quot;key&quot;: &quot;test&quot;, &quot;value&quot;: &quot;test&quot; }]'
http :8082/topics/kafka-rest.users Content-Type:application/vnd.kafka.avro.v2+json &lt; requests/produce-avro-message.json
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kafka-mqtt-proxy"><a class="header" href="#kafka-mqtt-proxy">Kafka MQTT Proxy</a></h1>
<p>MQTT Proxy enables MQTT clients to use the MQTT 3.1.1 protocol to publish data directly to Apache Kafka.</p>
<blockquote>
<p>⚠ This does not convert kafka into a MQTT broker, this aims to provide a simple way to publish/persist IoT data to Kafka.</p>
</blockquote>
<ul>
<li><a href="https://docs.confluent.io/platform/current/kafka-mqtt/intro.html">kafka mqtt</a></li>
<li><a href="https://docs.confluent.io/platform/current/kafka-mqtt/configuration_options.html">kafka mqtt settings</a></li>
<li>project location: <a href="https://github.com/sauljabin/kafka-sandbox/tree/main/kafka-mqtt">kafka-mqtt</a></li>
<li>kafka mqtt tcp port: <code>1884</code></li>
</ul>
<p>Run Kafka MQTT Proxy:</p>
<pre><code class="language-bash">cd kafka-mqtt
docker compose up -d
</code></pre>
<p>Publish a message:</p>
<pre><code class="language-bash">mqtt-cli pub -h kafka-mqtt -p 1884 -t 'house/room/temperature' -m '20C'
</code></pre>
<p>Consuming the data:</p>
<pre><code class="language-bash">kafka-cli kafka-console-consumer --from-beginning --group kafka-mqtt.consumer \
                                 --topic kafka-mqtt.temperature  \
                                 --bootstrap-server kafka1:9092 \
                                 --property print.key=true
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ports-table"><a class="header" href="#ports-table">Ports Table</a></h1>
<table><thead><tr><th>Service</th><th>Dns</th><th>Port</th></tr></thead><tbody>
<tr><td>AKHQ</td><td>localhost</td><td><a href="http://localhost:8080/">8080</a></td></tr>
<tr><td>Adminer</td><td>localhost</td><td><a href="http://localhost:9090/">9090</a></td></tr>
<tr><td>Mongo Express</td><td>localhost</td><td><a href="http://localhost:7070/">7070</a></td></tr>
<tr><td>Portainer</td><td>localhost</td><td><a href="http://localhost:9000/">9000</a></td></tr>
<tr><td>Portainer Tunnel</td><td>portainer</td><td>8000</td></tr>
<tr><td>Portainer Agent</td><td>portainer-agent</td><td>9001</td></tr>
<tr><td>MySQL</td><td>mysql</td><td>3306</td></tr>
<tr><td>MySQL</td><td>localhost</td><td>3306</td></tr>
<tr><td>PostgreSQL</td><td>postgres</td><td>5432</td></tr>
<tr><td>PostgreSQL</td><td>localhost</td><td>5432</td></tr>
<tr><td>MongoDB</td><td>mongo</td><td>27017</td></tr>
<tr><td>MongoDB</td><td>localhost</td><td>27017</td></tr>
<tr><td>Mosquitto</td><td>mosquitto</td><td>1883</td></tr>
<tr><td>Mosquitto</td><td>localhost</td><td>1883</td></tr>
<tr><td>Kafka 1</td><td>kafka1</td><td>9092</td></tr>
<tr><td>Kafka 1</td><td>localhost</td><td>19093</td></tr>
<tr><td>Kafka 2</td><td>kafka2</td><td>9092</td></tr>
<tr><td>Kafka 2</td><td>localhost</td><td>29093</td></tr>
<tr><td>Kafka 3</td><td>kafka3</td><td>9092</td></tr>
<tr><td>Kafka 3</td><td>localhost</td><td>39093</td></tr>
<tr><td>Zookeeper 1</td><td>zookeeper1</td><td>2181</td></tr>
<tr><td>Zookeeper 1</td><td>localhost</td><td>12181</td></tr>
<tr><td>Zookeeper 2</td><td>zookeeper2</td><td>2181</td></tr>
<tr><td>Zookeeper 2</td><td>localhost</td><td>22181</td></tr>
<tr><td>Zookeeper 3</td><td>zookeeper3</td><td>2181</td></tr>
<tr><td>Zookeeper 3</td><td>localhost</td><td>32181</td></tr>
<tr><td>Schema Registry</td><td>schema-registry</td><td>8081</td></tr>
<tr><td>Schema Registry</td><td>localhost</td><td>8081</td></tr>
<tr><td>Kafka REST</td><td>kafka-rest</td><td>8082</td></tr>
<tr><td>Kafka REST</td><td>localhost</td><td>8082</td></tr>
<tr><td>Kafka Connect</td><td>kafka-connect</td><td>8083</td></tr>
<tr><td>Kafka Connect</td><td>localhost</td><td>8083</td></tr>
<tr><td>Kafka MQTT</td><td>kafka-mqtt</td><td>1884</td></tr>
<tr><td>Kafka MQTT</td><td>localhost</td><td>1884</td></tr>
<tr><td>ksqlDB</td><td>ksqldb</td><td>8088</td></tr>
<tr><td>ksqlDB</td><td>localhost</td><td>8088</td></tr>
<tr><td>Kafka Clients Spring Boot</td><td>localhost</td><td>8585</td></tr>
</tbody></table>
<div style="break-before: page; page-break-before: always;"></div><h1 id="about-this-book"><a class="header" href="#about-this-book">About This Book</a></h1>
<p>This book is power by <a href="https://rust-lang.github.io/mdBook/index.html">mdBook</a>.</p>
<h2 id="developing-commands"><a class="header" href="#developing-commands">Developing Commands</a></h2>
<blockquote>
<p>You must to install <a href="https://www.rust-lang.org/tools/install">rust</a> first.</p>
</blockquote>
<p>Install <code>mdbook</code>:</p>
<pre><code class="language-bash">cargo install mdbook
</code></pre>
<p>Run local server:</p>
<pre><code class="language-bash">mdbook serve --open
</code></pre>
<p>Build statics:</p>
<pre><code class="language-bash">mdbook build
</code></pre>
<h2 id="using-docker"><a class="header" href="#using-docker">Using Docker</a></h2>
<p>Create docker image:</p>
<pre><code class="language-bash">docker build -t sauljabin/kafka-sandbox-book:latest -f docker/Dockerfile .
</code></pre>
<p>Running the book (<a href="http://localhost">open it in the web browser</a>):</p>
<pre><code class="language-bash">docker run --name kafka-sandbox-book -d -p 80:80 sauljabin/kafka-sandbox-book:latest
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
