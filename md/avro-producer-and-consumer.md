# Avro Producer and Consumer

Next, you will see how to serialize/deserialize messages using avro schemas.

### Other Links

- [confluent avro producer and consumer examples](https://docs.confluent.io/platform/current/schema-registry/fundamentals/serdes-develop/serdes-avro.html)
- [kafka consumer settings](https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html)
- [kafka producer settings](https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html)

### Avro Schema

<iframe width="560" height="315" src="https://www.youtube.com/embed/SZX9DM_gyOE"></iframe>

Avro allows us to serialize/deserialize messages. Here it's our example
avro schema:

```json
{{#include ../kafka-avro/src/main/avro/Supplier.avsc}}
```

### Create Topic

```bash
kafka-topics --create --bootstrap-server kafka1:9092 \
             --replication-factor 3 \
             --partitions 3 \
             --topic client.suppliers
```

### Produce

As you can see now we are using the autogenerated class `Supplier`.

```java
KafkaProducer<String, Supplier> producer = new KafkaProducer<>(props);

for (int i = 0; i < messages; i++) {
    Supplier supplier = createNew();
    ProducerRecord<String, Supplier> record = new ProducerRecord<>(
        topic,
        supplier.getId().toString(),
        supplier
    );
    producer.send(
        record,
        (metadata, exception) -> log.info("Producing message: {}", supplier)
    );
}
```

```bash
gradle kafka-avro-clients:run --args="produce client.suppliers 100"
```

### Consume

It is the same for the consumer, we are using the avro class `Supplier`.

```java
ConsumerRecords<String, Supplier> records = consumer.poll(Duration.ofMillis(500));

for (ConsumerRecord<String, Supplier> record : records) {
    log.info("Supplier ID: {}", record.key());
}
```

```bash
gradle kafka-avro-clients:run --args="consume client.suppliers"
```
